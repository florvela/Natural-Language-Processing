{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEnBiuLcukJc"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## RNN one-to-one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i96B2RF8uqEb"
   },
   "source": [
    "#### Datos\n",
    "El objecto es utilizar una serie de sucuencias númericas (datos sintéticos) para poner a prueba el uso de las redes RNN. Este ejemplo se inspiró en otro artículo, lo tienen como referencia en el siguiente link:\\\n",
    "[LINK](https://stackabuse.com/solving-sequence-problems-with-lstm-in-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lx0HQ-1RvJw9"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, SimpleRNN\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "10bFkG1YuaD9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datos X: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "datos y: [15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 285, 300]\n"
     ]
    }
   ],
   "source": [
    "# Generar datos sintéticos\n",
    "X = list()\n",
    "y = list()\n",
    "X = [x+1 for x in range(20)]\n",
    "\n",
    "# \"y\" (target) se obtiene como cada dato de entrada multiplicado por 15\n",
    "y = [x * 15 for x in X]\n",
    "\n",
    "print(\"datos X:\", X)\n",
    "print(\"datos y:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Oqabd-kYvza9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datos X: [[[ 1]]\n",
      "\n",
      " [[ 2]]\n",
      "\n",
      " [[ 3]]\n",
      "\n",
      " [[ 4]]\n",
      "\n",
      " [[ 5]]\n",
      "\n",
      " [[ 6]]\n",
      "\n",
      " [[ 7]]\n",
      "\n",
      " [[ 8]]\n",
      "\n",
      " [[ 9]]\n",
      "\n",
      " [[10]]\n",
      "\n",
      " [[11]]\n",
      "\n",
      " [[12]]\n",
      "\n",
      " [[13]]\n",
      "\n",
      " [[14]]\n",
      "\n",
      " [[15]]\n",
      "\n",
      " [[16]]\n",
      "\n",
      " [[17]]\n",
      "\n",
      " [[18]]\n",
      "\n",
      " [[19]]\n",
      "\n",
      " [[20]]]\n"
     ]
    }
   ],
   "source": [
    "# Cada dato X lo transformarmos en una matriz de 1 fila 1 columna (1x1)\n",
    "X = np.array(X).reshape(len(X), 1, 1)\n",
    "print(\"datos X:\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gYz6XpuyxBbQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.asanyarray(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VG3-d_NXwDGD"
   },
   "source": [
    "### 2 - Entrenar el modelo (RNN y LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OFeZEc63wOvJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RZir-NqDwWEo"
   },
   "outputs": [],
   "source": [
    "output_shape = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "QAhw8O9mwLR0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 22:39:33.215372: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 64)                4224      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,289\n",
      "Trainable params: 4,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Comenzamos con una RNN clásica\n",
    "# En general una celda RNN clásica ya no se utiliza, es solo a modo de ejemplo\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, activation='relu', input_shape=input_shape))\n",
    "model.add(Dense(output_shape))\n",
    "model.compile(loss='mse',\n",
    "              optimizer=\"Adam\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uSX93pkow2zM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 1s 77ms/step - loss: 20414.6602 - val_loss: 74726.8828\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 20309.7715 - val_loss: 74346.4844\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 20206.5273 - val_loss: 73976.5156\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 20107.2734 - val_loss: 73621.4297\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 20005.5605 - val_loss: 73274.7969\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 19903.3125 - val_loss: 72927.3594\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 19804.0508 - val_loss: 72569.5078\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 19700.1191 - val_loss: 72177.2344\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 19600.6250 - val_loss: 71772.8828\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 19479.9219 - val_loss: 71394.2969\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 19386.4766 - val_loss: 70986.4219\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 19265.3770 - val_loss: 70586.3594\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 19147.6094 - val_loss: 70183.5312\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 19034.3906 - val_loss: 69765.7109\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 18922.3184 - val_loss: 69335.2500\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 18798.1914 - val_loss: 68908.6094\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 18675.2715 - val_loss: 68475.2969\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 18562.5938 - val_loss: 68031.1016\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 18439.3008 - val_loss: 67595.3750\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 18318.9297 - val_loss: 67178.1250\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 18208.5840 - val_loss: 66786.8672\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 18102.7070 - val_loss: 66413.7188\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 18000.1484 - val_loss: 66048.5625\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 17894.9688 - val_loss: 65668.5781\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 17791.5020 - val_loss: 65293.6836\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 17689.8984 - val_loss: 64928.7227\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 17586.4492 - val_loss: 64573.8398\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 17489.2578 - val_loss: 64216.2031\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 17382.0059 - val_loss: 63861.3281\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 17281.6406 - val_loss: 63476.6211\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 17169.6562 - val_loss: 63057.0469\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 17067.4961 - val_loss: 62629.3867\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 16937.1367 - val_loss: 62198.5078\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 16819.8711 - val_loss: 61758.0078\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 16698.1680 - val_loss: 61334.1641\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 16569.7578 - val_loss: 60917.6250\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 16460.3730 - val_loss: 60471.9258\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 16336.8740 - val_loss: 60030.2539\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 16206.2871 - val_loss: 59575.7539\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 16089.8252 - val_loss: 59090.4805\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 15957.8008 - val_loss: 58605.0078\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 15809.6553 - val_loss: 58128.5469\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 15684.6963 - val_loss: 57614.3789\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 15527.4199 - val_loss: 57112.7422\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 15393.2803 - val_loss: 56584.5625\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 15236.8984 - val_loss: 56072.7266\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 15098.9629 - val_loss: 55488.2617\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 14930.0908 - val_loss: 54882.3008\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 14750.5020 - val_loss: 54301.7734\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 14586.3311 - val_loss: 53675.5625\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 14428.7344 - val_loss: 53029.4219\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 14232.1172 - val_loss: 52404.0156\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 14060.5840 - val_loss: 51742.7383\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 13870.4814 - val_loss: 51098.9180\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 13702.9746 - val_loss: 50481.3516\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 13525.0684 - val_loss: 49858.7734\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 13357.5781 - val_loss: 49216.4062\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 13178.8047 - val_loss: 48605.3438\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 13026.2549 - val_loss: 48024.6953\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 12859.4111 - val_loss: 47472.3906\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 12695.9629 - val_loss: 46922.7148\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 12543.5430 - val_loss: 46345.6914\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 12381.6475 - val_loss: 45780.1406\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 12236.0107 - val_loss: 45181.2891\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 12079.1299 - val_loss: 44609.8672\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11912.1387 - val_loss: 44068.3359\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11748.9180 - val_loss: 43527.3047\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11599.1416 - val_loss: 42902.2773\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 11416.4375 - val_loss: 42254.1641\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 11245.0879 - val_loss: 41574.5859\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 11051.3467 - val_loss: 40898.0000\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10873.4355 - val_loss: 40237.9180\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 10697.4795 - val_loss: 39599.8984\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10510.7295 - val_loss: 39003.4336\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 10350.7559 - val_loss: 38385.1875\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10167.1787 - val_loss: 37775.2656\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 9993.6455 - val_loss: 37111.1211\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9801.0029 - val_loss: 36451.3516\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9630.3047 - val_loss: 35783.3125\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9434.4199 - val_loss: 35132.3555\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 9265.0215 - val_loss: 34502.0781\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9090.8242 - val_loss: 33886.5312\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8927.5967 - val_loss: 33286.4648\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8771.7451 - val_loss: 32669.8633\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8589.9893 - val_loss: 32060.8594\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8415.8213 - val_loss: 31447.6758\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8259.0889 - val_loss: 30794.7031\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8065.2075 - val_loss: 30165.6055\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7897.9316 - val_loss: 29529.0781\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7720.5645 - val_loss: 28934.1289\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7569.9517 - val_loss: 28318.5215\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7382.4775 - val_loss: 27709.5703\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7222.8486 - val_loss: 27052.3848\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7041.7324 - val_loss: 26454.3301\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6887.9531 - val_loss: 25877.2070\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6720.4990 - val_loss: 25344.7148\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6575.3823 - val_loss: 24822.5938\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6427.4150 - val_loss: 24272.9180\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6285.3481 - val_loss: 23661.8496\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6127.1470 - val_loss: 23091.6484\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5957.7710 - val_loss: 22567.9023\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5817.5972 - val_loss: 22031.8945\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5667.5034 - val_loss: 21477.4629\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5520.0732 - val_loss: 20939.8047\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5371.3447 - val_loss: 20377.9473\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5218.4609 - val_loss: 19802.0820\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5067.3311 - val_loss: 19243.4141\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4920.8975 - val_loss: 18720.6523\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4769.1821 - val_loss: 18233.1270\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4634.1670 - val_loss: 17728.5273\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4496.1133 - val_loss: 17240.5176\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 4364.2056 - val_loss: 16765.8965\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4236.4971 - val_loss: 16295.1729\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 4106.2275 - val_loss: 15814.5176\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3975.3567 - val_loss: 15300.1621\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 3832.4304 - val_loss: 14804.6855\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3706.8279 - val_loss: 14314.3340\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3579.1106 - val_loss: 13825.4072\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3452.2131 - val_loss: 13379.6318\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3333.0837 - val_loss: 12972.3438\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3222.1843 - val_loss: 12585.4902\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 3110.9021 - val_loss: 12193.4004\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 3002.7913 - val_loss: 11769.8789\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2891.4292 - val_loss: 11347.2422\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2785.5173 - val_loss: 10940.6719\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2675.5750 - val_loss: 10506.3164\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2550.1335 - val_loss: 10076.5654\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2435.0527 - val_loss: 9639.0264\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2329.4382 - val_loss: 9203.3379\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2220.6782 - val_loss: 8787.0908\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2113.2397 - val_loss: 8418.5215\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2016.3231 - val_loss: 8058.3857\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1912.5999 - val_loss: 7732.8652\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1847.1891 - val_loss: 7401.6758\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1758.4454 - val_loss: 7112.0186\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1678.8564 - val_loss: 6856.0791\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1617.3350 - val_loss: 6606.4404\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1549.9020 - val_loss: 6358.0488\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1480.9780 - val_loss: 6116.9849\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1417.9902 - val_loss: 5851.2363\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1356.5380 - val_loss: 5586.4019\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1290.2866 - val_loss: 5335.5332\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1219.0829 - val_loss: 5097.1982\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1158.7627 - val_loss: 4849.1406\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1097.4420 - val_loss: 4606.3311\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1041.0596 - val_loss: 4383.2256\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 982.9208 - val_loss: 4172.5781\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 929.6527 - val_loss: 3983.7305\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 884.3766 - val_loss: 3808.9216\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 843.4816 - val_loss: 3648.1055\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 802.4178 - val_loss: 3499.2964\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 763.7332 - val_loss: 3359.2041\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 727.6804 - val_loss: 3209.1997\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 691.6337 - val_loss: 3055.1748\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 655.8821 - val_loss: 2913.4326\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 623.3345 - val_loss: 2784.3081\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 590.6229 - val_loss: 2668.2446\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 562.8936 - val_loss: 2560.6860\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 538.2477 - val_loss: 2452.4258\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 510.0381 - val_loss: 2339.4331\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 484.6254 - val_loss: 2235.3545\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 460.7852 - val_loss: 2137.4375\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 435.9696 - val_loss: 2048.7771\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 418.3761 - val_loss: 1957.4131\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 396.4897 - val_loss: 1874.3544\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 375.5623 - val_loss: 1795.5345\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 358.8271 - val_loss: 1707.0892\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 337.3496 - val_loss: 1625.1039\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 320.8879 - val_loss: 1541.8890\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 301.2763 - val_loss: 1469.2959\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 285.6591 - val_loss: 1400.3851\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 269.1034 - val_loss: 1339.0776\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 256.5944 - val_loss: 1278.1357\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 242.3981 - val_loss: 1220.1510\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 229.9965 - val_loss: 1166.0364\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 218.8056 - val_loss: 1114.7773\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 207.7538 - val_loss: 1065.5602\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 198.3027 - val_loss: 1017.3066\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 186.3672 - val_loss: 970.0560\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 176.5391 - val_loss: 921.5790\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 167.9032 - val_loss: 872.8214\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 157.7439 - val_loss: 830.6268\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 149.2210 - val_loss: 791.2812\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 141.7066 - val_loss: 754.5426\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 133.4175 - val_loss: 722.0355\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 127.4235 - val_loss: 690.3894\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 122.0249 - val_loss: 660.6036\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 115.1886 - val_loss: 633.4774\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 110.4694 - val_loss: 603.5670\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 104.9038 - val_loss: 577.3740\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 100.2820 - val_loss: 553.3060\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 95.4253 - val_loss: 531.1933\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 91.6428 - val_loss: 508.9904\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 87.4771 - val_loss: 487.8481\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 84.0179 - val_loss: 464.4325\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 79.8915 - val_loss: 443.5200\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 75.6782 - val_loss: 422.6378\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 72.4632 - val_loss: 401.2939\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 68.7344 - val_loss: 382.0908\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 65.5840 - val_loss: 362.0991\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 62.5887 - val_loss: 344.7720\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 60.0331 - val_loss: 328.4579\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 57.6866 - val_loss: 314.4823\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 55.5101 - val_loss: 302.4538\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 53.8878 - val_loss: 291.2132\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 52.2472 - val_loss: 281.2801\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 50.7404 - val_loss: 272.5193\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 49.5869 - val_loss: 264.2280\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 48.4496 - val_loss: 256.5039\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 47.2799 - val_loss: 249.6014\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 46.4724 - val_loss: 242.5756\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 45.3271 - val_loss: 235.8491\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 44.4732 - val_loss: 227.1276\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 43.3980 - val_loss: 218.7319\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 42.2479 - val_loss: 210.3922\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 41.3871 - val_loss: 202.4484\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 40.2719 - val_loss: 195.2739\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 39.4291 - val_loss: 189.2766\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 38.7207 - val_loss: 183.1138\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 38.0918 - val_loss: 175.8072\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 37.2082 - val_loss: 169.6790\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 36.6367 - val_loss: 163.0093\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 35.9543 - val_loss: 157.8206\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 35.5188 - val_loss: 153.3222\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 34.9679 - val_loss: 149.3754\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 34.6383 - val_loss: 144.4526\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 34.2013 - val_loss: 140.6110\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 33.8634 - val_loss: 137.5392\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 33.7063 - val_loss: 134.5407\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 33.3485 - val_loss: 132.3749\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 33.2260 - val_loss: 130.0031\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 32.9553 - val_loss: 127.9067\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 32.7956 - val_loss: 125.1225\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 32.5218 - val_loss: 122.8996\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 32.3848 - val_loss: 119.9605\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 32.1200 - val_loss: 117.5761\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 31.9629 - val_loss: 114.7998\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 31.7430 - val_loss: 112.2339\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.5981 - val_loss: 110.2236\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 31.4389 - val_loss: 108.4862\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.3114 - val_loss: 106.2760\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 31.1710 - val_loss: 104.6732\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 31.0526 - val_loss: 103.1031\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 30.9301 - val_loss: 100.6834\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 30.7759 - val_loss: 97.4591\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 30.6190 - val_loss: 94.2265\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 30.4716 - val_loss: 91.6410\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 30.3519 - val_loss: 89.3037\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 30.2275 - val_loss: 87.6557\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 30.1559 - val_loss: 86.4667\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 30.0910 - val_loss: 85.2942\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 30.0239 - val_loss: 84.5356\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 29.9758 - val_loss: 84.1247\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 29.9441 - val_loss: 83.6874\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 29.8975 - val_loss: 82.7823\n",
      "Epoch 256/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 23.9667"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1593\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1594\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1604\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1605\u001b[0m     )\n\u001b[0;32m-> 1606\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1619\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1621\u001b[0m }\n\u001b[1;32m   1622\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1945\u001b[0m ):\n\u001b[1;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(X, y, epochs=500, validation_split=0.2, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "anuBmCv0xNGA"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(hist.history['loss']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['loss'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['val_loss'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HK9QLOCN2Vt0"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(test_input, verbose=0)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5g-FIt5d2ZSU"
   },
   "outputs": [],
   "source": [
    "15*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88tdVCOyxcuy"
   },
   "outputs": [],
   "source": [
    "# Ensayo\n",
    "# x = 30\n",
    "# y_test = x * 15\n",
    "\n",
    "x_test = 30\n",
    "y_test = x_test * 15\n",
    "test_input = np.array([x_test])\n",
    "test_input = test_input.reshape((1, 1, 1))\n",
    "y_hat = model.predict(test_input, verbose=0)[0][0]\n",
    "\n",
    "print(\"y_test:\", y_test)\n",
    "print(\"y_hat:\", y_hat)\n",
    "\n",
    "model.evaluate(test_input, np.array([y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0-pi5qmVxav"
   },
   "outputs": [],
   "source": [
    "# Ahora probaremos con LSTM, qué es más compleja y por lo tanto\n",
    "# requiere más parámetros a entrenar\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(64, activation='relu', input_shape=input_shape))\n",
    "model2.add(Dense(output_shape))\n",
    "model2.compile(loss='mse',\n",
    "              optimizer=\"Adam\")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bp5r9gUEWLVf"
   },
   "outputs": [],
   "source": [
    "hist2 = model2.fit(X, y, epochs=500, validation_split=0.2, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNyQ__9fWUPC"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(hist2.history['loss']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist2.history['loss'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist2.history['val_loss'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuCV-UBhWNb3"
   },
   "outputs": [],
   "source": [
    "# Ensayo\n",
    "# x = 30\n",
    "# y_test = x * 15\n",
    "\n",
    "x_test = 30\n",
    "y_test = x_test * 15\n",
    "test_input = np.array([x_test])\n",
    "test_input = test_input.reshape((1, 1, 1))\n",
    "y_hat = model2.predict(test_input, verbose=0)[0][0]\n",
    "\n",
    "print(\"y_test:\", y_test)\n",
    "print(\"y_hat:\", y_hat)\n",
    "\n",
    "model2.evaluate(test_input, np.array([y_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEI5TjSFWeY8"
   },
   "source": [
    "Se puede observar que para un problema tan simple como este no hay mucha diferencia entre utilizar una RNN o LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AT8b9EfGyshD"
   },
   "source": [
    "### 3 - Multi-layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cH8Yd6WYyzQQ"
   },
   "outputs": [],
   "source": [
    "# En esta oportunidad se utilizarán dos layer LSTM. Para poder conectar\n",
    "# la primera layer con la segunda se debe colocar return_sequences=True\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(64, activation='relu', return_sequences=True, input_shape=input_shape))\n",
    "model3.add(LSTM(64, activation='relu'))\n",
    "model3.add(Dense(output_shape))\n",
    "model3.compile(loss='mse',\n",
    "              optimizer=\"Adam\")\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLtlpYpxzQZr"
   },
   "outputs": [],
   "source": [
    "hist3 = model3.fit(X, y, epochs=500, validation_split=0.2, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3Sl3cUJzZV_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(hist3.history['loss']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist3.history['loss'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist3.history['val_loss'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FveVOv2xzfkC"
   },
   "outputs": [],
   "source": [
    "# Ensayo\n",
    "# x = 30\n",
    "# y_test = x * 15\n",
    "\n",
    "x_test = 30\n",
    "y_test = x_test * 15\n",
    "test_input = np.array([x_test])\n",
    "test_input = test_input.reshape((1, 1, 1))\n",
    "y_hat = model3.predict(test_input, verbose=0)[0][0]\n",
    "\n",
    "print(\"y_test:\", y_test)\n",
    "print(\"y_hat:\", y_hat)\n",
    "\n",
    "model3.evaluate(test_input, np.array([y_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zd1g5MZfz5qB"
   },
   "source": [
    "### 4 - Conclusión\n",
    "Implementar un modelo basado en RNN o LSTM es muy sensillo, hay que tener en cuenta que al apilar varias layers hay que colocar el flag \"return_sequence\" en \"True\".\n",
    "El resultado alcanzado es bueno pero podría mejorarse agregando más layer LSTM o más layer Densas"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNtWEL/wkSrAU+5MYlOJ7sj",
   "collapsed_sections": [],
   "name": "4a - one-to-one.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
