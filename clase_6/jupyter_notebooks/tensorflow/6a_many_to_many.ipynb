{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## LSTM many-to-many"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqO0PRcFsPTe"
      },
      "source": [
        "### Datos\n",
        "El objecto es utilizar una serie de sucuencias númericas (datos sintéticos) para poner a prueba el uso de las redes LSTM. Este ejemplo se inspiró en otro artículo, lo tienen como referencia en el siguiente link:\\\n",
        "[LINK](https://stackabuse.com/solving-sequence-problems-with-lstm-in-keras-part-2/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq3YXak9sGHd"
      },
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM, SimpleRNN\n",
        "from keras.models import Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers import Bidirectional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9aNLZBDtA5J"
      },
      "source": [
        "# Generar datos sintéticos\n",
        "X = list()\n",
        "y = list()\n",
        "\n",
        "# En ambos casos \"X\" e \"y\" son vectores de números de 5 en 5\n",
        "X = [x for x in range(5, 301, 5)]\n",
        "y = [x+15 for x in X]\n",
        "\n",
        "print(f\"datos X (len={len(X)}):\", X)\n",
        "print(f\"datos y (len={len(y)}):\", y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ACkrI0GtEAM"
      },
      "source": [
        "# Se desea agrupar los datos de a 3 elementos\n",
        "X = np.array(X).reshape(len(X)//3, 3, 1)\n",
        "y = np.array(y).reshape(len(y)//3, 3, 1)\n",
        "print(\"datos X[0:2]:\", X[0:2])\n",
        "print(\"datos y[0:2]:\", y[0:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajykLcJ8tFfN"
      },
      "source": [
        "# Verificamos que la secuencia de entrada es igual a la secuencia de salida\n",
        "# en cuanto a dimensiones\n",
        "# Tendremos:\n",
        "#  --> veinte grupos de datos (rows) (20)\n",
        "#  --> cada grupo compuesto por tres elementos (3)\n",
        "#  --> cada elemento representado en una sola dimension (1)\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqznaoFYyDZC"
      },
      "source": [
        "# Cardinalidad (cantidad de elementos distintos en el dataset)\n",
        "data = np.append(X, y)\n",
        "len(np.unique(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### 2 - Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIhN4zRgwMtE"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "input_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNxu30D3wVAA"
      },
      "source": [
        "output_shape = y[0].shape\n",
        "output_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# input LSTM layer\n",
        "# Aquí se transformar las entradas en features\n",
        "# Retornarmos la secuencia para que la salida tenga la siguiente dimension:\n",
        "#   --> (tamaño batch, tamaño serie, tamaño elemento)\n",
        "# A diferencia de otra veces, estamos agregando el tamaño de la secuencia/serie\n",
        "model.add(LSTM(128, activation='relu', input_shape=(input_shape), return_sequences=True))\n",
        "\n",
        "# Al final tengo una salida (una secuencia) de 3 elementos juntos, \n",
        "# cada elemento de dimension 1:\n",
        "# --> (3x1)\n",
        "model.add(Dense(output_shape[-1]))\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=\"Adam\")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "hYr0PLxgmM45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFPJeRu9zMM9"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td9b0gySzW8D"
      },
      "source": [
        "Esta arquitectura comple lo solicitado, pero es bastante limitada y rebuscada. En el futuro y otros ejemplos veremos la arquitectura tipo encoder-decoder que es más flexible y \"simétrica\" que la utilizada en este caso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnlIx1Vezjwc"
      },
      "source": [
        "hist = model.fit(X, y, epochs=500, validation_split=0.2, batch_size=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVz1uug_zu2J"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['loss']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['loss'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['val_loss'], label='valid')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4_UQshIzw7o"
      },
      "source": [
        "# Ensayo\n",
        "x_test = [20, 25, 30]\n",
        "y_test = [x+15 for x in x_test]\n",
        "\n",
        "test_input = np.array([x_test])\n",
        "test_input = test_input.reshape((1, 3, 1))\n",
        "y_hat = model.predict(test_input, verbose=0)[0]\n",
        "\n",
        "print(\"y_test:\", y_test)\n",
        "print(\"y_hat:\", y_hat[0], y_hat[1], y_hat[2])\n",
        "\n",
        "model.evaluate(test_input, np.array([y_test]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}